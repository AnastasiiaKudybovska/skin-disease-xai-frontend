{
  "title": "Skin Condition Diagnosis",
  "selectImage": "Select Image",
  "backButton": "Back",
  "nextButton": "Continue",
  "resetButton": "Start Over",
  "reupload": "Reupload Image",
  "instructionSteps": {
    "upload": "Upload a skin photo",
    "uploadDesc": "Take a clear photo of the affected skin area and upload it to the system. You can drag and drop your image here.",
    "analysis": "Get a diagnosis",
    "analysisDesc": "The system will analyze the image and predict the most likely skin condition among 7 possible classes.",
    "results": "View explanations",
    "resultsDesc": "Choose one of the explainable AI methods to see which areas of the image the model focused on."
  },
  "notAuthTitle": "Log In for a Better Experience",
  "notAuthDesc": "You don’t need to log in to continue. However, signing in lets you keep track of your requests and access more features.",
  "logIn": "Log In",
  "continueWithoutLogin": "Continue Without logIn",
  "analysis_failed": "Image analysis failed. Please try again.",
  "diseaseLabels": {
    "vasc": "Vascular Lesion",
    "akiec": "Actinic Keratosis",
    "bcc": "Basal Cell Carcinoma",
    "nv": "Melanocytic Nevus",
    "mel": "Melanoma",
    "df": "Dermatofibroma",
    "bkl": "Benign Keratosis"
  },
  "analysisStep": {
    "analysisResults": "Diagnosis Results", 
    "uploadedImage": "Your Skin Image",
    "filename": "Filename: ",
    "viewXAIExplanation": "View XAI-based explanation",
    "topProbabilities": "Probability Distribution",    
    "confidence": "confidence",
    "mostLikelyCondition": "This is the most likely condition based on our analysis.",
    "note": "Note",
    "disclaimer": "This analysis is for informational purposes only and should not replace professional medical advice.",
    "no_results": "No results were obtained from the image analysis. Please try again.",
    "unknown": "Unknown class",
    "lowConfidenceTitle": "Low Confidence Results",
    "lowConfidenceMessage": "We couldn't analyze your image with sufficient confidence. Please try again with a better quality image.",
    "lowConfidenceError": "Analysis confidence is too low ",
    "highestPredicted": "Highest predicted class",
    "suggestionsTitle": "Suggestions",
    "suggestion1": "Use better lighting",
    "suggestion2": "Make sure the focus is clear",
    "suggestion3": "Capture the affected area closer",
    "tryAgainButton": "Try Again"
  },
  "xaiMethods": {
    "title": "Explainable AI Method",
    "subtitle": "Select a method to understand why this diagnosis was made",
    "generateExplanation": "Generate Explanation",
    "gradcamDesc": "Visualizes which image regions influenced the decision using gradients.",
    "limeDesc": "Explains predictions by creating local interpretable models.",
    "shapDesc": "Shows how much each part of the image contributed to the prediction using game theory concepts.",
    "anchorDesc": "Identifies important regions that, if removed, would change the model’s decision.",
    "igDesc": "Determines which pixels had the most impact by analyzing gradient changes.",
    "explanationTitle": "Explanation",
    "noExplanationImage": "Explanation visualization not available",
    "predictionDetails": "Classification Details",
    "predictedClass": "Predicted disease",
    "confidence": "Confidence",
    "backToMethods": "Back to Methods",
    "gradcamDescLong": "Grad-CAM (Gradient-weighted Class Activation Mapping) highlights the areas that most influenced the AI’s decision by using gradient information from the final convolutional layer.",
    "limeDescLong": "LIME (Local Interpretable Model-agnostic Explanations) explains why the AI made a specific prediction by intentionally altering parts of the image and building a simple model to show which areas had the most impact on the decision.",
    "shapDescLong": "SHAP (SHapley Additive exPlanations) estimates the contribution of each pixel to the model's prediction based on game theory.",
    "anchorDescLong": "Anchor identifies the smallest parts of the image that independently ensure a stable prediction.",
    "anchorDescLongToggle": "Show segments",
    "igTitle": "Integrated Gradients",
    "igDescLong": "Integrated Gradients show how the prediction changes as the input transitions from a baseline to the actual image.",
    "igDescLongToggle": "Show only gradients (without outlines)",
    "requestError": "An error occurred while processing the request. Please try again later.",
    "noImageError": "No image was uploaded. Please select a file before proceeding.",
    "showHeatmap": "Show importance heatmap",
    "showOverlay": "Show explanations",
    "waiting": "Please wait. Explanation processing may take a few minutes...",
    "adjustHeatmapOpacity": "Adjust heatmap opacity",
    "success": "Explanation created successfully",
    "heatmapOpacity": "Heatmap opacity",
    "interpretationTitle": "How to Interpret the Results?",
    "howToUseTitle": "How to Use This Explanation?",
    "gradcamInterpretation": "Red, yellow and blue areas indicate regions that strongly support the predicted diagnosis. Pink and purple areas are less important. The intensity shows the contribution of each region to the decision.",
    "gradcamHowToUse": "Focus on the highlighted areas to understand which features the model considers important. Compare with other methods for comprehensive analysis.",
    "limeInterpretation": "Areas highlighted in green positively influence the prediction, while red areas contradict it. The intensity shows the strength of influence.",
    "limeHowToUse": "Examine the highlighted image segments to see which areas were most influential in determining the disease. On the importance heatmap, yellow and red shades positively affected the decision, while purple and blue shades had a negative impact.",
    "shapInterpretation": "Blue, green areas increase the probability of the predicted class, while red areas decrease it. The slider adjusts the heatmap opacity.",
    "shapHowToUse": "Adjust the opacity to blend the heatmap with the original image. Compare SHAP values with other methods.",
    "anchorInterpretation": "Highlighted areas represent the minimal features that indicate this diagnosis. Other areas are less important for this decision.",
    "anchorHowToUse": "The most important image regions are displayed. You can also examine other image segments that were used to evaluate the most significant areas.",
    "igInterpretation": "Bright contours indicate the image areas with the greatest influence. The intensity shows the magnitude of contribution.",
    "igHowToUse": "Switch between gradients and overlays to see different representations of feature importance. Darker areas had less impact on the resulting diagnosis, while brighter areas had more influence."
  }
  
}